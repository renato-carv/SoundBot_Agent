import json
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, SystemMessage
from src.config.settings import settings
from src.utils.logger import logger

class AIService:
    def __init__(self):
        self.llm = ChatGroq(
            model="llama-3.1-8b-instant",
            temperature=0.7,
            groq_api_key=settings.GROQ_API_KEY
        )
        logger.info("AIService initialized with model llama-3.1-8b-instant")

    def interpret_request(self, text: str) -> dict:
        """
        Interpreta a mensagem do usu√°rio e retorna JSON com a√ß√£o, humor, artista, m√∫sica e g√™nero.
        """
        system_prompt = """
        Voc√™ √© um assistente musical que interpreta pedidos dos usu√°rios e converte em JSON estruturado.
        Retorne SOMENTE o JSON no formato:

        {
            "acao": "recomendar" | "buscar_artista" | "buscar_musica" | "desconhecido",
            "humor": "feliz" | "triste" | "animado" | "calmo" | "rom√¢ntico" | "energ√©tico" | "nost√°lgico" | "festa" | "focado" | null,
            "genero": string | null,
            "artista": string | null,
            "musica": string | null
        }
        """
        messages = [SystemMessage(content=system_prompt), HumanMessage(content=text)]
        logger.info(f"Interpreting user request: '{text}'")

        try:
            response = self.llm.invoke(messages)
            content = response.content.strip()

            # Remove delimitadores ```json se existirem
            if content.startswith("```"):
                content = content.replace("```json", "").replace("```", "").strip()

            parsed = json.loads(content)
            logger.info(f"Successfully interpreted request: {parsed}")
            return parsed
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing failed: {e} | Response content: {content}")
        except Exception as e:
            logger.exception(f"Error interpreting request: {e}")

        # fallback padr√£o
        return {
            "acao": "desconhecido",
            "humor": None,
            "genero": None,
            "artista": None,
            "musica": None
        }

    def generate_reply(self, context: str, recommendations: list, mood: str = None, artist: str = None, song: str = None) -> str:
        """
        Gera a resposta do bot, retornando apenas o texto amig√°vel e humano (sem listar m√∫sicas no reply)
        """
        system_prompt = """
        Voc√™ √© um assistente musical amig√°vel e natural.
        Retorne **apenas** um JSON v√°lido no formato:
        {
            "reply": "Mensagem simp√°tica e humana, sem citar os nomes das m√∫sicas",
            "mood": "<humor_detectado ou null>",
            "recommendations": ["m√∫sica - artista", ...]
        }

        Regras:
        - Nunca coloque os nomes das m√∫sicas no reply
        - As recomenda√ß√µes v√£o no campo recommendations
        - Texto em portugu√™s e natural
        - Sem markdown ou blocos de c√≥digo
        """
        user_context = f"""
        Contexto: {context}
        Humor detectado: {mood}
        Artista: {artist}
        M√∫sica: {song}
        Recomenda√ß√µes: {recommendations if recommendations else 'nenhuma encontrada'}
        """

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_context)
        ]

        try:
            response = self.llm.invoke(messages)
            content = response.content.strip()

            if content.startswith("```"):
                content = content.replace("```json", "").replace("```", "").strip()

            data = json.loads(content)
            reply = data.get("reply", "Espero que goste dessas m√∫sicas! üé∂")
            return reply
        except json.JSONDecodeError:
            logger.warning(f"LLM did not return JSON. Raw: {response.content}")
            return "Aqui est√£o algumas m√∫sicas que acho que voc√™ vai gostar! üéß"
        except Exception as e:
            logger.error(f"Error generating reply: {e}", exc_info=True)
            return "Tive um probleminha para formular a resposta agora, mas posso tentar de novo se quiser!"
